<html>

<head>
<meta http-equiv=Content-Type content="text/html;">
<meta name="description" content="Project homepage for text.curtain"/>
<title>
text.curtain by daniel c. howe
</title>
<LINK href="dch.css" rel="stylesheet" type="text/css">
</head>

<body lang=EN-US link=#333c4d vlink=#333c4d alink=#333c4d>

<table width=600 border=0>
<tr><td width=40>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td><div class=Section1>

<table><tr><td width=250><br>
<span style='font-size:11.0pt;color:#333c4d;font-family:arial'><b>text.curtain</b></span>
<span style='font-size:8.0pt;font-family:
Verdana;mso-bidi-font-family:Arial;color:#333333;layout-grid-mode:both'><br><br>'text.curtain'</span></i><span style='font-size:8.0pt;font-family:Verdana;mso-bidi-font-family:Arial; color:#333333;layout-grid-mode:both;'> 
explores relationships between poetic text and ludic play via an
interactively evolving recombinant text. Projected on a wall-size screen,
text.curtain presents a physics-based 'spring-mass' interface that
organically responds to the interactions of multiple simultaneous users. As
the piece is disrupted and letters wash back and forth, a granular synthesis
engine provides realtime aural feedback. Tension is created through the
simultaneous desire of users to both disrupt the existing text via 'play' and
to 'read' the piece as it evolves and recombines in response.</span><p>&nbsp;
</td>
<td>&nbsp;</td>

<td><br><a href="http://mrl.nyu.edu/~dhowe/textcurtain"><img border=1
width=240 src="img/curtain.risd.jpg"></a><br>
<center>
<span
style='font-size:6.5pt;color:#333c4d;font-family:verdana'><b>text.curtain at Rhode Island School of Design</b></span>
</center>
</td>
</tr>
</table>

<table><tr><td width=505>
<span style='font-size:8.0pt;font-family:Verdana;color:#333333'>As a user approaches the piece they are presented with fourteen
lines. Depending on the version, either video motion-tracking (as below) or multiple
track-balls (as above,) measure users' interactions, allowing disruption of the letters and lines via movement.  As the entropy (or disorder) of the system
increases and lines fragments and layer atop each another, readability is
increasingly obscured until a threshold is reached and a state change occurs,
with the existing text shifting up and away and a newly selected line appearing
at bottom. As the new line appears, the system settles into a stability once
again, affording a new reading of the ever-evolving text (there are
30-factorial or nearly 3^30 potential poems in the work, virtually guaranteeing
that none will repeat in a single day).</span></p>

</td>
</tr>
</table>

<center>
<!--a href="http://mrl.nyu.edu/~dhowe/textcurtain"--><img  border=1 width=540
height=388 src="img/image002.jpg"><!--/a--><p>

<!--span style='font-size:8.0pt;color:#333c4d;font-family:Arial'><b>visit the 
<a href="applet.html" target=_new>demo applet</a> and
<a href="http://mrl.nyu.edu/%7Edhowe/video/text.curtain.mp4" target=_new>video
documentation</a></b></span-->

<p>&nbsp;<p>
<span style='font-size:6.0pt;color:#333c4d;font-family:verdana'>
&copy;canazon</span>
</center>


<!--span
style='font-size:8.0pt;color:#333c4d;font-family:Arial'><b>Display</b></span><br><span style='font-size:9.0pt;font-family:Verdana;color:#333333'>The piece requires ~2-5 hours of setup depending on ease of mounting camera (above screen) and projector (behind viewer) and calibration of tracking software.
Depending on lighting conditions, a back screen (behind the audience) may also
be necessary to aid in video tracking. For hardware, the work requires a PC
&amp;
mini-speaker setup (provided by artist), as well as a video camera (firewire)
and
high-lumen projector (provided by the venue if possible, by the artist if
necessary). A ladder and basic tools for mounting are also required. No
special
cartons or boxes are necessary and items will be hand-delivered by artist at
setup time. No internet connectivity is required. Depending on the venue, the
work�s sound component may be disabled. <o:p></o:p></span></p-->


<!--b style='mso-bidi-font-weight:normal'><span style='font-family:Verdana;
mso-bidi-font-family:Arial;color:#333333;layout-grid-mode:both'><o:p>&nbsp;</o:p></span></b></p-->

<!--span style='font-size:11.0pt;color:#333c4d;font-family:Arial'><b>Artist
Bio</b></span><br><span
style='font-size:9.0pt;font-family:Verdana;mso-bidi-font-family:Arial;
color:#333333'>Daniel C Howe is a digital artist &amp; researcher at NYU's
Media Research Lab. His interests include generative systems for artistic
practice &amp; social aspects of technology design. Current projects include
the ALTK, a toolkit for affective language generation &amp; Values-In-Design,
a
developing methodology for integrating social values in technical systems
design. In addition to a background in creative writing and fine arts, Daniel
has master's degrees in Computer Science (U. Washington) and Interactive Media
(NYU/ITP), as well as over 10 years experience as a programmer, software
architect &amp; educator. He is a regularly exhibiting digital artist with
recent work featured in ELO �06, E-Fest 2006, Leonardo, ASCI '05,
Experimental
Typography, Thailand New Media Arts Festival, PixxelPoint, Artbots, Ars
Electronica, &amp; Terra Acoustica. He is the 2005/06 recipient of the Brown
Fellowship for Electronic Writing. </span><span style='font-family:Verdana;
color:#333333'><o:p></o:p></span></p-->
</div>
</td></tr>
</table>

</body>

</html>
